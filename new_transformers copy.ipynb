{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 799/799 [00:00<00:00, 1685.71it/s]\n"]}],"source":["import matplotlib.pyplot as plt\n","from tqdm import trange\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","\n","\n","# Assuming the npy files are named 'delta_0.npy', 'delta_1.npy', etc.\n","\n","start_n = 0\n","end_n = 799\n","\n","# Specify the index of the item to plot\n","item_index = 2500\n","\n","# Initialize a list to store the item values\n","item_values = []\n","vector_values = []\n","\n","# Load the item values from the npy files\n","for i in trange(start_n, end_n):\n","    vector = np.load(f'/user/as6154/dissert/L12_half_data/delta_{i}.npy')\n","\n","    item_values.append(vector[item_index])\n","    vector_values.append(vector)\n","\n","vector_values = np.array(vector_values)\n","# # Plot the item values\n","# plt.figure(figsize=(10, 6))\n","# plt.plot(item_values, label=f'Item {item_index}')\n","\n","# plt.xlabel('File Index')\n","# plt.ylabel('Item Value')\n","# plt.title(f'Item {item_index} from NPY Files')\n","# plt.legend()\n","# plt.show()"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/plain":["4096"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["len(vector)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Binned values loaded from pickle file (first 10): [[99999 11065 11065 ... 11065 11065 11065]\n"," [99999 11065 11065 ... 11065 11065 11065]\n"," [99999 11065 11065 ... 11065 11065 11065]\n"," ...\n"," [99999 11065 11065 ... 11065 11065 11065]\n"," [99999 11065 11065 ... 11065 11065 11065]\n"," [99999 11065 11065 ... 11065 11065 11065]]\n","Binned values (last 10): [[11065 11065 11065 ... 11065 11065 11065]\n"," [11065 11065 11065 ... 11065 11065 11065]\n"," [11065 11065 11065 ... 11065 11065 11065]\n"," ...\n"," [11065 11065 11065 ... 11065 11065 11065]\n"," [11065 11065 11065 ... 11065 11065 11065]\n"," [11065 11065 11065 ... 11065 11065 11065]]\n"]}],"source":["import pickle\n","number_of_bins = 100000\n","dir_path = \"/user/as6154/dissert/szhalf_L12_delta_-2_to_0_interval_400_secondDelta_1_to_1_interval_1_data\"\n","\n","# Define the path to save the pickle file\n","pickle_file_path = f'{dir_path}/{number_of_bins}_binned_values.pkl'\n","with open(pickle_file_path, 'rb') as f:\n","    binned_values_loaded = pickle.load(f)\n","\n","print(f\"Binned values loaded from pickle file (first 10): {binned_values_loaded[:10]}\")\n","print(f\"Binned values (last 10): {binned_values_loaded[-10:]}\")  # Display first 10 binned values for reference"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["\n","from sklearn.model_selection import train_test_split\n","\n","sequence_length = 10\n","batch_size = 4\n","\n","class HighDimensionalDataset(Dataset):\n","    def __init__(self, data, n_items = 1000, random = False):\n","        self.data = data\n","        self.random = random\n","    \n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        if self.random:\n","            start_index = np.random.randint(0, len(self.data) - sequence_length)\n","        else:\n","            start_index = min(idx, len(self.data) - sequence_length)\n","        sequence = self.data[start_index : start_index + sequence_length]\n","        return torch.tensor(sequence, dtype=torch.float32)\n","\n","\n","\n","# Split the data into training and testing sets\n","train_data = binned_values_loaded\n","test_data = binned_values_loaded\n","\n","# TODO: But this test_dataset would also work if it's overfitting?\n","train_dataset = HighDimensionalDataset(train_data, n_items = 1000, random = True)\n","test_dataset = HighDimensionalDataset(test_data, n_items = 1000, random = False)\n","\n","\n","# Create dataloaders for training and testing\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([10, 4096])"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset[100].shape"]},{"cell_type":"markdown","metadata":{},"source":["Setting:\n","\n","1. We have a sequence 800 data, that is across delta changing, each item is vector dim 4096.\n","2. I want to predict next data, conditioning on previous data. \n","3. So my input and output is dim 4096. \n","\n","Idea is to \n","\n","\n","-----\n","\n","Normal language models take in batch of text, text is in high dimension, but it's a number alone.\n","so it's BxN.\n","\n","Our's is BxNxD.\n","\n","So i need to embed the D to 1D?\n","\n","\n","Can we embed continous instead of quantize? \n","- but we need to tokenize first right?\n","- unless i train my own tokenizer with bpe?\n","- so we shouldnt?"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["4096"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset[0].shape[1]"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[2024-06-26 22:06:00,446] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n","torch.Size([4, 10, 4096])\n"]}],"source":["# Garg inspired model\n","from transformers import GPT2Config, GPT2Model\n","import torch.nn as nn\n","\n","\n","class Transformer(nn.Module):\n","    def __init__(self, n_dims, n_positions, n_embd=4096, n_layer=12, n_head=4):\n","        super(Transformer, self).__init__()\n","        configuration = GPT2Config(\n","            n_positions=2 * n_positions,\n","            n_embd=n_embd,\n","            n_layer=n_layer,\n","            n_head=n_head,\n","            resid_pdrop=0.0,\n","            embd_pdrop=0.0,\n","            attn_pdrop=0.0,\n","            use_cache=False,\n","        )\n","        self.name = f\"gpt2_embd={n_embd}_layer={n_layer}_head={n_head}\"\n","\n","        self.n_positions = n_positions\n","        self.n_dims = n_dims\n","        \n","        self._read_in = nn.Linear(n_dims, n_embd)\n","        self._backbone = GPT2Model(configuration)\n","        self._read_out = nn.Linear(n_embd, n_dims)\n","\n","    def forward(self, x):\n","        embeds = self._read_in(x)\n","        output = self._backbone(inputs_embeds = embeds).last_hidden_state\n","        prediction = self._read_out(output)\n","        return prediction\n","    \n","n_dims = train_dataset[0].shape[1]\n","n_positions = 1024\n","\n","model = Transformer(n_dims, n_positions)\n","\n","input_data = torch.randn(batch_size, sequence_length, n_dims)\n","\n","output = model(input_data)\n","print(output.shape)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([4, 10, 4096])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["next(iter(train_dataloader)).shape"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([1, 10, 4096])"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["next(iter(test_dataloader)).shape"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandrewsiah\u001b[0m (\u001b[33mhong-exploration\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["wandb version 0.17.3 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.15.12"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/user/as6154/dissert/wandb/run-20240626_220645-hpr4s7qb</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/hong-exploration/GPT_QFT/runs/hpr4s7qb' target=\"_blank\">lively-totem-30</a></strong> to <a href='https://wandb.ai/hong-exploration/GPT_QFT' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/hong-exploration/GPT_QFT' target=\"_blank\">https://wandb.ai/hong-exploration/GPT_QFT</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/hong-exploration/GPT_QFT/runs/hpr4s7qb' target=\"_blank\">https://wandb.ai/hong-exploration/GPT_QFT/runs/hpr4s7qb</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["  1%|          | 1/100 [00:28<46:14, 28.02s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 124377784.0\n","Lowest Loss at index: 266, Loss: 123781632.0\n","Epoch [1/100], Step [100/100], Loss: 124013880.0\n"]},{"name":"stderr","output_type":"stream","text":["  2%|▏         | 2/100 [00:53<43:18, 26.51s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 123385712.0\n","Lowest Loss at index: 266, Loss: 122791840.0\n","Epoch [2/100], Step [100/100], Loss: 123163096.0\n"]},{"name":"stderr","output_type":"stream","text":["  3%|▎         | 3/100 [01:19<42:23, 26.22s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 122344224.0\n","Lowest Loss at index: 266, Loss: 121752664.0\n","Epoch [3/100], Step [100/100], Loss: 122116552.0\n"]},{"name":"stderr","output_type":"stream","text":["  4%|▍         | 4/100 [01:47<43:26, 27.15s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 121248056.0\n","Lowest Loss at index: 266, Loss: 120659032.0\n","Epoch [4/100], Step [100/100], Loss: 121259280.0\n"]},{"name":"stderr","output_type":"stream","text":["  5%|▌         | 5/100 [02:15<43:28, 27.46s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 120100712.0\n","Lowest Loss at index: 266, Loss: 119514528.0\n","Epoch [5/100], Step [100/100], Loss: 120112424.0\n"]},{"name":"stderr","output_type":"stream","text":["  6%|▌         | 6/100 [02:44<43:45, 27.93s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 118906824.0\n","Lowest Loss at index: 266, Loss: 118323560.0\n","Epoch [6/100], Step [100/100], Loss: 118457120.0\n"]},{"name":"stderr","output_type":"stream","text":["  7%|▋         | 7/100 [03:12<43:25, 28.01s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 117671648.0\n","Lowest Loss at index: 266, Loss: 117091224.0\n","Epoch [7/100], Step [100/100], Loss: 117684176.0\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 8/100 [03:40<42:57, 28.02s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 116399976.0\n","Lowest Loss at index: 266, Loss: 115822320.0\n","Epoch [8/100], Step [100/100], Loss: 116168848.0\n"]},{"name":"stderr","output_type":"stream","text":["  9%|▉         | 9/100 [04:08<42:17, 27.89s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 115096592.0\n","Lowest Loss at index: 266, Loss: 114522056.0\n","Epoch [9/100], Step [100/100], Loss: 114996384.0\n"]},{"name":"stderr","output_type":"stream","text":[" 10%|█         | 10/100 [04:35<41:36, 27.74s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 113765776.0\n","Lowest Loss at index: 266, Loss: 113194880.0\n","Epoch [10/100], Step [100/100], Loss: 113439984.0\n"]},{"name":"stderr","output_type":"stream","text":[" 11%|█         | 11/100 [05:03<40:52, 27.55s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 112411592.0\n","Lowest Loss at index: 266, Loss: 111844184.0\n","Epoch [11/100], Step [100/100], Loss: 112199976.0\n"]},{"name":"stderr","output_type":"stream","text":[" 12%|█▏        | 12/100 [05:30<40:11, 27.40s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 111038208.0\n","Lowest Loss at index: 266, Loss: 110473760.0\n","Epoch [12/100], Step [100/100], Loss: 110830304.0\n"]},{"name":"stderr","output_type":"stream","text":[" 13%|█▎        | 13/100 [05:57<39:39, 27.35s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 109648456.0\n","Lowest Loss at index: 266, Loss: 109087832.0\n","Epoch [13/100], Step [100/100], Loss: 109330696.0\n"]},{"name":"stderr","output_type":"stream","text":[" 14%|█▍        | 14/100 [06:24<39:15, 27.39s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 108245992.0\n","Lowest Loss at index: 266, Loss: 107688776.0\n","Epoch [14/100], Step [100/100], Loss: 108038472.0\n"]},{"name":"stderr","output_type":"stream","text":[" 15%|█▌        | 15/100 [06:51<38:36, 27.25s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 106833512.0\n","Lowest Loss at index: 266, Loss: 106279528.0\n","Epoch [15/100], Step [100/100], Loss: 106620800.0\n"]},{"name":"stderr","output_type":"stream","text":[" 16%|█▌        | 16/100 [07:19<38:27, 27.47s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 105413704.0\n","Lowest Loss at index: 266, Loss: 104863264.0\n","Epoch [16/100], Step [100/100], Loss: 105313064.0\n"]},{"name":"stderr","output_type":"stream","text":[" 17%|█▋        | 17/100 [07:47<38:03, 27.51s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 103989280.0\n","Lowest Loss at index: 266, Loss: 103442704.0\n","Epoch [17/100], Step [100/100], Loss: 103687384.0\n"]},{"name":"stderr","output_type":"stream","text":[" 18%|█▊        | 18/100 [08:14<37:25, 27.39s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 102562600.0\n","Lowest Loss at index: 266, Loss: 102019640.0\n","Epoch [18/100], Step [100/100], Loss: 102122216.0\n"]},{"name":"stderr","output_type":"stream","text":[" 19%|█▉        | 19/100 [08:42<37:02, 27.43s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 101135712.0\n","Lowest Loss at index: 266, Loss: 100596648.0\n","Epoch [19/100], Step [100/100], Loss: 100927816.0\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 20/100 [09:09<36:32, 27.40s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 99710576.0\n","Lowest Loss at index: 266, Loss: 99175336.0\n","Epoch [20/100], Step [100/100], Loss: 99507216.0\n"]},{"name":"stderr","output_type":"stream","text":[" 21%|██        | 21/100 [09:36<35:57, 27.31s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 98289112.0\n","Lowest Loss at index: 266, Loss: 97757568.0\n","Epoch [21/100], Step [100/100], Loss: 98198728.0\n"]},{"name":"stderr","output_type":"stream","text":[" 22%|██▏       | 22/100 [10:03<35:28, 27.29s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 96873128.0\n","Lowest Loss at index: 266, Loss: 96345728.0\n","Epoch [22/100], Step [100/100], Loss: 96887272.0\n"]},{"name":"stderr","output_type":"stream","text":[" 23%|██▎       | 23/100 [10:30<34:59, 27.27s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 95464432.0\n","Lowest Loss at index: 266, Loss: 94940536.0\n","Epoch [23/100], Step [100/100], Loss: 95163120.0\n"]},{"name":"stderr","output_type":"stream","text":[" 24%|██▍       | 24/100 [10:58<34:31, 27.26s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 94064040.0\n","Lowest Loss at index: 266, Loss: 93543960.0\n","Epoch [24/100], Step [100/100], Loss: 93857336.0\n"]},{"name":"stderr","output_type":"stream","text":[" 25%|██▌       | 25/100 [11:25<33:57, 27.17s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 92673760.0\n","Lowest Loss at index: 266, Loss: 92157296.0\n","Epoch [25/100], Step [100/100], Loss: 92362152.0\n"]},{"name":"stderr","output_type":"stream","text":[" 26%|██▌       | 26/100 [11:51<33:13, 26.94s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 91294592.0\n","Lowest Loss at index: 266, Loss: 90781800.0\n","Epoch [26/100], Step [100/100], Loss: 90994048.0\n"]},{"name":"stderr","output_type":"stream","text":[" 27%|██▋       | 27/100 [12:17<32:25, 26.65s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 89927296.0\n","Lowest Loss at index: 266, Loss: 89418208.0\n","Epoch [27/100], Step [100/100], Loss: 89940912.0\n"]},{"name":"stderr","output_type":"stream","text":[" 28%|██▊       | 28/100 [12:43<31:41, 26.41s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 88573408.0\n","Lowest Loss at index: 266, Loss: 88068008.0\n","Epoch [28/100], Step [100/100], Loss: 88177720.0\n"]},{"name":"stderr","output_type":"stream","text":[" 29%|██▉       | 29/100 [13:09<31:02, 26.23s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 87233512.0\n","Lowest Loss at index: 266, Loss: 86731944.0\n","Epoch [29/100], Step [100/100], Loss: 87141608.0\n"]},{"name":"stderr","output_type":"stream","text":[" 30%|███       | 30/100 [13:34<30:24, 26.06s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 85908520.0\n","Lowest Loss at index: 266, Loss: 85410920.0\n","Epoch [30/100], Step [100/100], Loss: 85826064.0\n"]},{"name":"stderr","output_type":"stream","text":[" 31%|███       | 31/100 [14:00<29:47, 25.90s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 84599600.0\n","Lowest Loss at index: 266, Loss: 84105688.0\n","Epoch [31/100], Step [100/100], Loss: 84418368.0\n"]},{"name":"stderr","output_type":"stream","text":[" 32%|███▏      | 32/100 [14:26<29:16, 25.83s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 83307240.0\n","Lowest Loss at index: 266, Loss: 82816720.0\n","Epoch [32/100], Step [100/100], Loss: 82944704.0\n"]},{"name":"stderr","output_type":"stream","text":[" 33%|███▎      | 33/100 [14:51<28:50, 25.83s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 82031672.0\n","Lowest Loss at index: 266, Loss: 81544712.0\n","Epoch [33/100], Step [100/100], Loss: 81733928.0\n"]},{"name":"stderr","output_type":"stream","text":[" 34%|███▍      | 34/100 [15:17<28:22, 25.79s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 80773760.0\n","Lowest Loss at index: 266, Loss: 80290496.0\n","Epoch [34/100], Step [100/100], Loss: 80695008.0\n"]},{"name":"stderr","output_type":"stream","text":[" 35%|███▌      | 35/100 [15:43<27:51, 25.71s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 79533856.0\n","Lowest Loss at index: 266, Loss: 79054224.0\n","Epoch [35/100], Step [100/100], Loss: 79448000.0\n"]},{"name":"stderr","output_type":"stream","text":[" 36%|███▌      | 36/100 [16:08<27:23, 25.68s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 78312688.0\n","Lowest Loss at index: 266, Loss: 77836832.0\n","Epoch [36/100], Step [100/100], Loss: 78233112.0\n"]},{"name":"stderr","output_type":"stream","text":[" 37%|███▋      | 37/100 [16:34<26:58, 25.69s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 77110632.0\n","Lowest Loss at index: 266, Loss: 76638136.0\n","Epoch [37/100], Step [100/100], Loss: 77024424.0\n"]},{"name":"stderr","output_type":"stream","text":[" 38%|███▊      | 38/100 [16:59<26:27, 25.60s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 75927864.0\n","Lowest Loss at index: 266, Loss: 75458920.0\n","Epoch [38/100], Step [100/100], Loss: 75652760.0\n"]},{"name":"stderr","output_type":"stream","text":[" 39%|███▉      | 39/100 [17:25<26:03, 25.63s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 74764600.0\n","Lowest Loss at index: 266, Loss: 74298824.0\n","Epoch [39/100], Step [100/100], Loss: 74497240.0\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|████      | 40/100 [17:51<25:37, 25.62s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 73621032.0\n","Lowest Loss at index: 266, Loss: 73158960.0\n","Epoch [40/100], Step [100/100], Loss: 73538792.0\n"]},{"name":"stderr","output_type":"stream","text":[" 41%|████      | 41/100 [18:16<25:07, 25.56s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 72497608.0\n","Lowest Loss at index: 266, Loss: 72038944.0\n","Epoch [41/100], Step [100/100], Loss: 72421712.0\n"]},{"name":"stderr","output_type":"stream","text":[" 42%|████▏     | 42/100 [18:41<24:38, 25.49s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 71394600.0\n","Lowest Loss at index: 266, Loss: 70939592.0\n","Epoch [42/100], Step [100/100], Loss: 71317480.0\n"]},{"name":"stderr","output_type":"stream","text":[" 43%|████▎     | 43/100 [19:07<24:15, 25.53s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 70312360.0\n","Lowest Loss at index: 266, Loss: 69860768.0\n","Epoch [43/100], Step [100/100], Loss: 70323088.0\n"]},{"name":"stderr","output_type":"stream","text":[" 44%|████▍     | 44/100 [19:33<23:50, 25.54s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 69250536.0\n","Lowest Loss at index: 266, Loss: 68802432.0\n","Epoch [44/100], Step [100/100], Loss: 69083464.0\n"]},{"name":"stderr","output_type":"stream","text":[" 45%|████▌     | 45/100 [19:58<23:26, 25.57s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 68209520.0\n","Lowest Loss at index: 266, Loss: 67764256.0\n","Epoch [45/100], Step [100/100], Loss: 67941352.0\n"]},{"name":"stderr","output_type":"stream","text":[" 46%|████▌     | 46/100 [20:24<23:00, 25.57s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 67189280.0\n","Lowest Loss at index: 266, Loss: 66747536.0\n","Epoch [46/100], Step [100/100], Loss: 67022592.0\n"]},{"name":"stderr","output_type":"stream","text":[" 47%|████▋     | 47/100 [20:49<22:33, 25.54s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 66189840.0\n","Lowest Loss at index: 266, Loss: 65751076.0\n","Epoch [47/100], Step [100/100], Loss: 66199736.0\n"]},{"name":"stderr","output_type":"stream","text":[" 48%|████▊     | 48/100 [21:15<22:07, 25.52s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 65211884.0\n","Lowest Loss at index: 266, Loss: 64776244.0\n","Epoch [48/100], Step [100/100], Loss: 65133576.0\n"]},{"name":"stderr","output_type":"stream","text":[" 49%|████▉     | 49/100 [21:40<21:41, 25.52s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 64254804.0\n","Lowest Loss at index: 266, Loss: 63822324.0\n","Epoch [49/100], Step [100/100], Loss: 64175160.0\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|█████     | 50/100 [22:06<21:16, 25.53s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 63318480.0\n","Lowest Loss at index: 266, Loss: 62889168.0\n","Epoch [50/100], Step [100/100], Loss: 62997128.0\n"]},{"name":"stderr","output_type":"stream","text":[" 51%|█████     | 51/100 [22:31<20:51, 25.54s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 62402440.0\n","Lowest Loss at index: 266, Loss: 61976200.0\n","Epoch [51/100], Step [100/100], Loss: 62322092.0\n"]},{"name":"stderr","output_type":"stream","text":[" 52%|█████▏    | 52/100 [22:57<20:27, 25.58s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 61507528.0\n","Lowest Loss at index: 266, Loss: 61084352.0\n","Epoch [52/100], Step [100/100], Loss: 61434588.0\n"]},{"name":"stderr","output_type":"stream","text":[" 53%|█████▎    | 53/100 [23:23<20:02, 25.59s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 60633360.0\n","Lowest Loss at index: 266, Loss: 60213432.0\n","Epoch [53/100], Step [100/100], Loss: 60471608.0\n"]},{"name":"stderr","output_type":"stream","text":[" 54%|█████▍    | 54/100 [23:48<19:36, 25.57s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 59780240.0\n","Lowest Loss at index: 266, Loss: 59363112.0\n","Epoch [54/100], Step [100/100], Loss: 59542784.0\n"]},{"name":"stderr","output_type":"stream","text":[" 55%|█████▌    | 55/100 [24:14<19:10, 25.57s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 58947964.0\n","Lowest Loss at index: 266, Loss: 58534124.0\n","Epoch [55/100], Step [100/100], Loss: 58734948.0\n"]},{"name":"stderr","output_type":"stream","text":[" 56%|█████▌    | 56/100 [24:39<18:44, 25.55s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 58136256.0\n","Lowest Loss at index: 266, Loss: 57725364.0\n","Epoch [56/100], Step [100/100], Loss: 58058340.0\n"]},{"name":"stderr","output_type":"stream","text":[" 57%|█████▋    | 57/100 [25:05<18:19, 25.56s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 57344788.0\n","Lowest Loss at index: 266, Loss: 56936564.0\n","Epoch [57/100], Step [100/100], Loss: 57188848.0\n"]},{"name":"stderr","output_type":"stream","text":[" 58%|█████▊    | 58/100 [25:31<17:57, 25.65s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 56573728.0\n","Lowest Loss at index: 266, Loss: 56168144.0\n","Epoch [58/100], Step [100/100], Loss: 56489536.0\n"]},{"name":"stderr","output_type":"stream","text":[" 59%|█████▉    | 59/100 [25:56<17:31, 25.64s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 55823228.0\n","Lowest Loss at index: 266, Loss: 55420196.0\n","Epoch [59/100], Step [100/100], Loss: 55659628.0\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|██████    | 60/100 [26:22<17:06, 25.66s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 55093072.0\n","Lowest Loss at index: 266, Loss: 54692416.0\n","Epoch [60/100], Step [100/100], Loss: 54962352.0\n"]},{"name":"stderr","output_type":"stream","text":[" 61%|██████    | 61/100 [26:48<16:39, 25.64s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 54383260.0\n","Lowest Loss at index: 266, Loss: 53984940.0\n","Epoch [61/100], Step [100/100], Loss: 54072748.0\n"]},{"name":"stderr","output_type":"stream","text":[" 62%|██████▏   | 62/100 [27:13<16:17, 25.73s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 53693368.0\n","Lowest Loss at index: 266, Loss: 53297284.0\n","Epoch [62/100], Step [100/100], Loss: 53542628.0\n"]},{"name":"stderr","output_type":"stream","text":[" 63%|██████▎   | 63/100 [27:39<15:50, 25.70s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 53022996.0\n","Lowest Loss at index: 266, Loss: 52629360.0\n","Epoch [63/100], Step [100/100], Loss: 52870144.0\n"]},{"name":"stderr","output_type":"stream","text":[" 64%|██████▍   | 64/100 [28:05<15:21, 25.61s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 52372564.0\n","Lowest Loss at index: 266, Loss: 51981560.0\n","Epoch [64/100], Step [100/100], Loss: 52305780.0\n"]},{"name":"stderr","output_type":"stream","text":[" 65%|██████▌   | 65/100 [28:30<14:55, 25.59s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 51742036.0\n","Lowest Loss at index: 266, Loss: 51353396.0\n","Epoch [65/100], Step [100/100], Loss: 51593140.0\n"]},{"name":"stderr","output_type":"stream","text":[" 66%|██████▌   | 66/100 [28:56<14:30, 25.59s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 51131116.0\n","Lowest Loss at index: 266, Loss: 50744668.0\n","Epoch [66/100], Step [100/100], Loss: 50987968.0\n"]},{"name":"stderr","output_type":"stream","text":[" 67%|██████▋   | 67/100 [29:23<14:23, 26.17s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 50539812.0\n","Lowest Loss at index: 266, Loss: 50155508.0\n","Epoch [67/100], Step [100/100], Loss: 50473152.0\n"]},{"name":"stderr","output_type":"stream","text":[" 68%|██████▊   | 68/100 [29:49<13:53, 26.06s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 49967496.0\n","Lowest Loss at index: 266, Loss: 49585268.0\n","Epoch [68/100], Step [100/100], Loss: 49824732.0\n"]},{"name":"stderr","output_type":"stream","text":[" 69%|██████▉   | 69/100 [30:16<13:36, 26.34s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 49414012.0\n","Lowest Loss at index: 266, Loss: 49033736.0\n","Epoch [69/100], Step [100/100], Loss: 49345016.0\n"]},{"name":"stderr","output_type":"stream","text":[" 70%|███████   | 70/100 [30:43<13:16, 26.54s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 48879592.0\n","Lowest Loss at index: 266, Loss: 48501424.0\n","Epoch [70/100], Step [100/100], Loss: 48742580.0\n"]},{"name":"stderr","output_type":"stream","text":[" 71%|███████   | 71/100 [31:10<12:54, 26.71s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 48364360.0\n","Lowest Loss at index: 266, Loss: 47988216.0\n","Epoch [71/100], Step [100/100], Loss: 48159720.0\n"]},{"name":"stderr","output_type":"stream","text":[" 72%|███████▏  | 72/100 [31:37<12:32, 26.86s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 47867816.0\n","Lowest Loss at index: 266, Loss: 47493732.0\n","Epoch [72/100], Step [100/100], Loss: 47797152.0\n"]},{"name":"stderr","output_type":"stream","text":[" 73%|███████▎  | 73/100 [32:05<12:08, 26.99s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 47390104.0\n","Lowest Loss at index: 266, Loss: 47017828.0\n","Epoch [73/100], Step [100/100], Loss: 47173768.0\n"]},{"name":"stderr","output_type":"stream","text":[" 74%|███████▍  | 74/100 [32:32<11:43, 27.05s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 46930488.0\n","Lowest Loss at index: 266, Loss: 46560148.0\n","Epoch [74/100], Step [100/100], Loss: 46935000.0\n"]},{"name":"stderr","output_type":"stream","text":[" 75%|███████▌  | 75/100 [32:59<11:16, 27.08s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 46488964.0\n","Lowest Loss at index: 266, Loss: 46120376.0\n","Epoch [75/100], Step [100/100], Loss: 46429480.0\n"]},{"name":"stderr","output_type":"stream","text":[" 76%|███████▌  | 76/100 [33:26<10:50, 27.11s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 46065796.0\n","Lowest Loss at index: 266, Loss: 45698804.0\n","Epoch [76/100], Step [100/100], Loss: 45850588.0\n"]},{"name":"stderr","output_type":"stream","text":[" 77%|███████▋  | 77/100 [33:53<10:23, 27.11s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 45660804.0\n","Lowest Loss at index: 266, Loss: 45295508.0\n","Epoch [77/100], Step [100/100], Loss: 45521740.0\n"]},{"name":"stderr","output_type":"stream","text":[" 78%|███████▊  | 78/100 [34:21<09:57, 27.17s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 45274032.0\n","Lowest Loss at index: 266, Loss: 44910164.0\n","Epoch [78/100], Step [100/100], Loss: 45187944.0\n"]},{"name":"stderr","output_type":"stream","text":[" 79%|███████▉  | 79/100 [34:48<09:30, 27.16s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 44905204.0\n","Lowest Loss at index: 266, Loss: 44542948.0\n","Epoch [79/100], Step [100/100], Loss: 44765036.0\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|████████  | 80/100 [35:15<09:05, 27.29s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 44553976.0\n","Lowest Loss at index: 266, Loss: 44193068.0\n","Epoch [80/100], Step [100/100], Loss: 44338192.0\n"]},{"name":"stderr","output_type":"stream","text":[" 81%|████████  | 81/100 [35:42<08:38, 27.27s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 44220376.0\n","Lowest Loss at index: 266, Loss: 43860776.0\n","Epoch [81/100], Step [100/100], Loss: 43995704.0\n"]},{"name":"stderr","output_type":"stream","text":[" 82%|████████▏ | 82/100 [36:10<08:11, 27.28s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 43904584.0\n","Lowest Loss at index: 266, Loss: 43546168.0\n","Epoch [82/100], Step [100/100], Loss: 43702828.0\n"]},{"name":"stderr","output_type":"stream","text":[" 83%|████████▎ | 83/100 [36:37<07:43, 27.25s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 43606400.0\n","Lowest Loss at index: 266, Loss: 43249128.0\n","Epoch [83/100], Step [100/100], Loss: 43414100.0\n"]},{"name":"stderr","output_type":"stream","text":[" 84%|████████▍ | 84/100 [37:04<07:14, 27.17s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 43325732.0\n","Lowest Loss at index: 266, Loss: 42969628.0\n","Epoch [84/100], Step [100/100], Loss: 43167496.0\n"]},{"name":"stderr","output_type":"stream","text":[" 85%|████████▌ | 85/100 [37:31<06:45, 27.01s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 43062576.0\n","Lowest Loss at index: 266, Loss: 42707564.0\n","Epoch [85/100], Step [100/100], Loss: 42989568.0\n"]},{"name":"stderr","output_type":"stream","text":[" 86%|████████▌ | 86/100 [37:57<06:17, 26.97s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 42816248.0\n","Lowest Loss at index: 266, Loss: 42462396.0\n","Epoch [86/100], Step [100/100], Loss: 42746268.0\n"]},{"name":"stderr","output_type":"stream","text":[" 87%|████████▋ | 87/100 [38:24<05:47, 26.74s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 42587140.0\n","Lowest Loss at index: 266, Loss: 42234148.0\n","Epoch [87/100], Step [100/100], Loss: 42449008.0\n"]},{"name":"stderr","output_type":"stream","text":[" 88%|████████▊ | 88/100 [38:49<05:17, 26.44s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 42375300.0\n","Lowest Loss at index: 266, Loss: 42023100.0\n","Epoch [88/100], Step [100/100], Loss: 42304544.0\n"]},{"name":"stderr","output_type":"stream","text":[" 89%|████████▉ | 89/100 [39:15<04:47, 26.17s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 42180652.0\n","Lowest Loss at index: 266, Loss: 41829260.0\n","Epoch [89/100], Step [100/100], Loss: 42110244.0\n"]},{"name":"stderr","output_type":"stream","text":[" 90%|█████████ | 90/100 [39:41<04:19, 25.99s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 42003188.0\n","Lowest Loss at index: 266, Loss: 41652416.0\n","Epoch [90/100], Step [100/100], Loss: 41799016.0\n"]},{"name":"stderr","output_type":"stream","text":[" 91%|█████████ | 91/100 [40:06<03:53, 25.93s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 41842828.0\n","Lowest Loss at index: 266, Loss: 41492840.0\n","Epoch [91/100], Step [100/100], Loss: 41704908.0\n"]},{"name":"stderr","output_type":"stream","text":[" 92%|█████████▏| 92/100 [40:32<03:26, 25.85s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 41699276.0\n","Lowest Loss at index: 266, Loss: 41349932.0\n","Epoch [92/100], Step [100/100], Loss: 41474848.0\n"]},{"name":"stderr","output_type":"stream","text":[" 93%|█████████▎| 93/100 [40:57<03:00, 25.74s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 41572692.0\n","Lowest Loss at index: 266, Loss: 41223828.0\n","Epoch [93/100], Step [100/100], Loss: 41360136.0\n"]},{"name":"stderr","output_type":"stream","text":[" 94%|█████████▍| 94/100 [41:23<02:34, 25.68s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 41463168.0\n","Lowest Loss at index: 266, Loss: 41114780.0\n","Epoch [94/100], Step [100/100], Loss: 41320828.0\n"]},{"name":"stderr","output_type":"stream","text":[" 95%|█████████▌| 95/100 [41:49<02:08, 25.66s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 41370648.0\n","Lowest Loss at index: 266, Loss: 41022648.0\n","Epoch [95/100], Step [100/100], Loss: 41206664.0\n"]},{"name":"stderr","output_type":"stream","text":[" 96%|█████████▌| 96/100 [42:14<01:42, 25.67s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 41295140.0\n","Lowest Loss at index: 266, Loss: 40947464.0\n","Epoch [96/100], Step [100/100], Loss: 41165936.0\n"]},{"name":"stderr","output_type":"stream","text":[" 97%|█████████▋| 97/100 [42:40<01:16, 25.62s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 41236668.0\n","Lowest Loss at index: 266, Loss: 40889204.0\n","Epoch [97/100], Step [100/100], Loss: 41170000.0\n"]},{"name":"stderr","output_type":"stream","text":[" 98%|█████████▊| 98/100 [43:05<00:51, 25.61s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 41194104.0\n","Lowest Loss at index: 266, Loss: 40846812.0\n","Epoch [98/100], Step [100/100], Loss: 41041440.0\n"]},{"name":"stderr","output_type":"stream","text":[" 99%|█████████▉| 99/100 [43:31<00:25, 25.54s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 41168480.0\n","Lowest Loss at index: 266, Loss: 40821296.0\n","Epoch [99/100], Step [100/100], Loss: 41097188.0\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 100/100 [43:56<00:00, 26.37s/it]"]},{"name":"stdout","output_type":"stream","text":["Highest Loss at index: 0, Loss: 41159860.0\n","Lowest Loss at index: 266, Loss: 40812708.0\n","Epoch [100/100], Step [100/100], Loss: 40955736.0\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["import wandb\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","import pandas as pd\n","\n","\n","wandb.init(project=\"GPT_QFT\")\n","loss_fn = nn.MSELoss()\n","device = \"cuda:1\"\n","num_epochs = 100\n","eval_steps = 100\n","\n","optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-4)\n","\n","# optimizer = AdamW(model.parameters(), lr=1e-4)\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=100, num_training_steps=len(train_dataloader) * num_epochs)\n","\n","\n","\n","def evaluate_model(model, test_dataloader, device, loss_fn):\n","    loss_df = pd.DataFrame()\n","    model.eval()\n","    with torch.no_grad():\n","        loss_array = []\n","        for i, (test_input_seq) in enumerate(test_dataloader):\n","            test_target_seq = test_input_seq[:, 1:, :]\n","            test_input_seq = test_input_seq.to(device)\n","            test_target_seq = test_target_seq.to(device)\n","\n","            test_output = model(test_input_seq)\n","            test_output = test_output[:, 1:, :]\n","\n","            test_loss = loss_fn(test_output, test_target_seq)\n","            loss_array.append((i, test_loss.item()))\n","        loss_df = pd.DataFrame(loss_array, columns=['Index', 'Loss'])\n","        loss_df.drop(columns=['Index'], inplace=True)\n","        loss_df = loss_df.transpose()\n","        loss_df.to_csv('loss_data_n2_100000.csv', mode='a', header=False, index=False)\n","\n","        loss_array.sort(key=lambda x: x[1], reverse=True)\n","        print(f'Highest Loss at index: {loss_array[0][0]}, Loss: {loss_array[0][1]}')\n","        print(f'Lowest Loss at index: {loss_array[-1][0]}, Loss: {loss_array[-1][1]}')\n","        wandb.log({\"Highest Loss Index\": loss_array[0][0], \"Lowest Loss Index\": loss_array[-1][0]})\n","    model.train()\n","\n","for epoch in trange(num_epochs):\n","    for i, (input_seq) in enumerate(train_dataloader):\n","\n","        target_seq = input_seq[:, 1:, :]\n","\n","        model.to(device)\n","        input_seq = input_seq.to(device)\n","        target_seq = target_seq.to(device)\n","        output = model(input_seq)\n","        output = output[:, 1:, :]\n","\n","        loss = loss_fn(output, target_seq)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","\n","        if (i+1) % eval_steps == 0:\n","            evaluate_model(model, test_dataloader, device, loss_fn)\n","            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_dataloader)}], Loss: {loss.item()}')\n","            wandb.log({\"Loss\": loss.item()})"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"pytorch","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":2}
