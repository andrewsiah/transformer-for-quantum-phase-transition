Training...
Epoch 0

















































Training Iterations:  98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎  | 49/50 [04:40<00:05,  5.60s/it]
Training Iterations: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [04:51<00:00,  5.83s/it]


























Training Iterations:  52%|██████████████████████████████████████████████████████████████████████▏                                                                | 26/50 [02:28<02:16,  5.70s/it]
Traceback (most recent call last):
  File "/user/as6154/dissert/new_transformers.py", line 154, in <module>
    loss = loss_fn(output, target_seq)
  File "/user/as6154/.conda/envs/poetry/lib/python3.9/site-packages/torch/optim/lr_scheduler.py", line 75, in wrapper
    return wrapped(*args, **kwargs)
  File "/user/as6154/.conda/envs/poetry/lib/python3.9/site-packages/torch/optim/optimizer.py", line 391, in wrapper
    out = func(*args, **kwargs)
  File "/user/as6154/.conda/envs/poetry/lib/python3.9/site-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/user/as6154/.conda/envs/poetry/lib/python3.9/site-packages/torch/optim/adamw.py", line 188, in step
    adamw(
  File "/user/as6154/.conda/envs/poetry/lib/python3.9/site-packages/torch/optim/adamw.py", line 340, in adamw
    func(
  File "/user/as6154/.conda/envs/poetry/lib/python3.9/site-packages/torch/optim/adamw.py", line 550, in _multi_tensor_adamw
    torch._foreach_lerp_(device_exp_avgs, device_grads, 1 - beta1)
KeyboardInterrupt