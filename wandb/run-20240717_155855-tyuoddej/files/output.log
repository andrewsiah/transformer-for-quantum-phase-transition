Training...
Epoch 0
Training Iterations:   0%|                  | 0/10 [00:03<?, ?it/s]
Traceback (most recent call last):
  File "/user/as6154/dissert/gpt2.py", line 182, in <module>
    model.to(device)
  File "/user/as6154/.conda/envs/diss/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1173, in to
    return self._apply(convert)
  File "/user/as6154/.conda/envs/diss/lib/python3.9/site-packages/torch/nn/modules/module.py", line 779, in _apply
    module._apply(fn)
  File "/user/as6154/.conda/envs/diss/lib/python3.9/site-packages/torch/nn/modules/module.py", line 779, in _apply
    module._apply(fn)
  File "/user/as6154/.conda/envs/diss/lib/python3.9/site-packages/torch/nn/modules/module.py", line 779, in _apply
    module._apply(fn)
  [Previous line repeated 2 more times]
  File "/user/as6154/.conda/envs/diss/lib/python3.9/site-packages/torch/nn/modules/module.py", line 804, in _apply
    param_applied = fn(param)
  File "/user/as6154/.conda/envs/diss/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1159, in convert
    return t.to(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 192.00 MiB. GPU  has a total capacity of 79.14 GiB of which 151.62 MiB is free. Process 623581 has 8.01 GiB memory in use. Process 657077 has 68.92 GiB memory in use. Including non-PyTorch memory, this process has 2.04 GiB memory in use. Of the allocated memory 1.62 GiB is allocated by PyTorch, and 17.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)